{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Melbourne Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import os, sys, time, pickle, tempfile\n",
    "import math, random, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.linalg import kron\n",
    "\n",
    "from pystruct.models import EdgeFeatureGraphCRF\n",
    "from pystruct.learners import OneSlackSSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "fpoi = os.path.join(data_dir, 'poi-Melb-all.csv')\n",
    "fvisits = os.path.join(data_dir, 'userVisits-Melb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load POI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_all = pd.read_csv(fpoi)\n",
    "poi_all.set_index('poiID', inplace=True)\n",
    "#poi_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts Precinct</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.82167</td>\n",
       "      <td>144.96778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Docklands</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.81700</td>\n",
       "      <td>144.94600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Government Precinct</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.81190</td>\n",
       "      <td>144.97300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Little Italy</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.79972</td>\n",
       "      <td>144.96694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RMIT City</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.80778</td>\n",
       "      <td>144.96333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name        Category  Latitude  Longitude\n",
       "poiID                                                          \n",
       "0            Arts Precinct  City precincts -37.82167  144.96778\n",
       "1                Docklands  City precincts -37.81700  144.94600\n",
       "2      Government Precinct  City precincts -37.81190  144.97300\n",
       "3             Little Italy  City precincts -37.79972  144.96694\n",
       "4                RMIT City  City precincts -37.80778  144.96333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df = poi_all.copy()\n",
    "poi_df.drop('poiURL', axis=1, inplace=True)\n",
    "poi_df.rename(columns={'poiName':'Name', 'poiTheme':'Category', 'poiLat':'Latitude', 'poiLon':'Longitude'}, \\\n",
    "              inplace=True)\n",
    "poi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Trajectory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visits = pd.read_csv(fvisits, sep=';')\n",
    "#visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoID</th>\n",
       "      <th>userID</th>\n",
       "      <th>dateTaken</th>\n",
       "      <th>poiID</th>\n",
       "      <th>trajID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9588963220</td>\n",
       "      <td>67774014@N00</td>\n",
       "      <td>1377408461</td>\n",
       "      <td>8</td>\n",
       "      <td>3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703949177</td>\n",
       "      <td>79925938@N00</td>\n",
       "      <td>1183135485</td>\n",
       "      <td>20</td>\n",
       "      <td>3975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>775049707</td>\n",
       "      <td>79925938@N00</td>\n",
       "      <td>1183823546</td>\n",
       "      <td>18</td>\n",
       "      <td>3977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8687823797</td>\n",
       "      <td>35558720@N03</td>\n",
       "      <td>1364043697</td>\n",
       "      <td>25</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2676185</td>\n",
       "      <td>79925938@N00</td>\n",
       "      <td>1104369016</td>\n",
       "      <td>71</td>\n",
       "      <td>3919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      photoID        userID   dateTaken  poiID  trajID\n",
       "0  9588963220  67774014@N00  1377408461      8    3333\n",
       "1   703949177  79925938@N00  1183135485     20    3975\n",
       "2   775049707  79925938@N00  1183823546     18    3977\n",
       "3  8687823797  35558720@N03  1364043697     25    1487\n",
       "4     2676185  79925938@N00  1104369016     71    3919"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits.drop(['poiTheme', 'poiFreq'], axis=1, inplace=True)\n",
    "visits.rename(columns={'seqID':'trajID'}, inplace=True)\n",
    "visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute POI Statistics DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Compute POI Visit Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of photos associated with each POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#photos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #photos\n",
       "poiID         \n",
       "0          102\n",
       "1          139\n",
       "2          304\n",
       "3          138\n",
       "4          349"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_photo = visits[['photoID', 'poiID']].copy().groupby('poiID').agg(np.size)\n",
    "poi_photo.rename(columns={'photoID':'#photos'}, inplace=True)\n",
    "poi_photo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the visit duration at each POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trajID</th>\n",
       "      <th>poiID</th>\n",
       "      <th>arrivalTime</th>\n",
       "      <th>departureTime</th>\n",
       "      <th>poiDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1226726126</td>\n",
       "      <td>1226726126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1205332532</td>\n",
       "      <td>1205332541</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1205342722</td>\n",
       "      <td>1205342729</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>1205374109</td>\n",
       "      <td>1205374109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>1205417265</td>\n",
       "      <td>1205417265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trajID  poiID  arrivalTime  departureTime  poiDuration\n",
       "0       0     25   1226726126     1226726126            0\n",
       "1       1     58   1205332532     1205332541            9\n",
       "2       1     66   1205342722     1205342729            7\n",
       "3       2     59   1205374109     1205374109            0\n",
       "4       3     58   1205417265     1205417265            0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_duration = visits[['dateTaken', 'poiID', 'trajID']].copy().groupby(['trajID', 'poiID']).agg([np.min, np.max])\n",
    "poi_duration.columns = poi_duration.columns.droplevel()\n",
    "poi_duration.rename(columns={'amin':'arrivalTime', 'amax':'departureTime'}, inplace=True)\n",
    "poi_duration.reset_index(inplace=True)\n",
    "poi_duration['poiDuration'] = poi_duration['departureTime'] - poi_duration['arrivalTime']\n",
    "poi_duration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering out zero duration records.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_duration = poi_duration[poi_duration['poiDuration'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the median and summation of POI visit duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medianDuration(sec)</th>\n",
       "      <th>totalDuration(sec)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332.5</td>\n",
       "      <td>24600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438.5</td>\n",
       "      <td>42491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1835.0</td>\n",
       "      <td>141155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971.5</td>\n",
       "      <td>61945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>829.0</td>\n",
       "      <td>137382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       medianDuration(sec)  totalDuration(sec)\n",
       "poiID                                         \n",
       "0                    332.5               24600\n",
       "1                    438.5               42491\n",
       "2                   1835.0              141155\n",
       "3                   1971.5               61945\n",
       "4                    829.0              137382"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_duration_stats = poi_duration[['poiID', 'poiDuration']].copy().groupby('poiID').agg([np.median, np.sum])\n",
    "poi_duration_stats.columns = poi_duration_stats.columns.droplevel()\n",
    "poi_duration_stats.rename(columns={'median':'medianDuration(sec)', 'sum':'totalDuration(sec)'}, inplace=True)\n",
    "poi_duration_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of visits at each POI by all users and by distinct users.  \n",
    "**NOTE: we assume NO loops/subtours appear in trajectories**, \n",
    "so a specific user would visit a certain POI in a specific trajectory at most once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>trajID</th>\n",
       "      <th>poiID</th>\n",
       "      <th>#photosAtPOIInTraj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10058801@N06</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  trajID  poiID  #photosAtPOIInTraj\n",
       "0  10058801@N06       0     25                   1\n",
       "1  10087938@N02       1     58                   2\n",
       "2  10087938@N02       1     66                   2\n",
       "3  10087938@N02       2     59                   1\n",
       "4  10087938@N02       3     58                   1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_visits = visits[['userID', 'trajID', 'poiID', 'photoID']].copy().groupby(['userID','trajID','poiID']).agg(np.size)\n",
    "poi_visits.reset_index(inplace=True)\n",
    "poi_visits.rename(columns={'photoID':'#photosAtPOIInTraj'}, inplace=True)\n",
    "poi_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#distinctUsers</th>\n",
       "      <th>#visits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #distinctUsers  #visits\n",
       "poiID                         \n",
       "0                  64       73\n",
       "1                  39       52\n",
       "2                  83      116\n",
       "3                  44       54\n",
       "4                  50       84"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_visits_stats = poi_visits[['userID', 'poiID']].copy().groupby('poiID').agg([pd.Series.nunique, np.size])\n",
    "poi_visits_stats.columns = poi_visits_stats.columns.droplevel()\n",
    "poi_visits_stats.rename(columns={'nunique':'#distinctUsers', 'size':'#visits'}, inplace=True)\n",
    "poi_visits_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy visit statistics to POI dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_df['#photos'] = 0\n",
    "poi_df['#visits'] = 0\n",
    "poi_df['#distinctUsers'] = 0\n",
    "poi_df['medianDuration(sec)'] = 0.0\n",
    "poi_df['totalDuration(sec)'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>#photos</th>\n",
       "      <th>#visits</th>\n",
       "      <th>#distinctUsers</th>\n",
       "      <th>medianDuration(sec)</th>\n",
       "      <th>totalDuration(sec)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts Precinct</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.82167</td>\n",
       "      <td>144.96778</td>\n",
       "      <td>102</td>\n",
       "      <td>73</td>\n",
       "      <td>64</td>\n",
       "      <td>332.5</td>\n",
       "      <td>24600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Docklands</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.81700</td>\n",
       "      <td>144.94600</td>\n",
       "      <td>139</td>\n",
       "      <td>52</td>\n",
       "      <td>39</td>\n",
       "      <td>438.5</td>\n",
       "      <td>42491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Government Precinct</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.81190</td>\n",
       "      <td>144.97300</td>\n",
       "      <td>304</td>\n",
       "      <td>116</td>\n",
       "      <td>83</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>141155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Little Italy</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.79972</td>\n",
       "      <td>144.96694</td>\n",
       "      <td>138</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>1971.5</td>\n",
       "      <td>61945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RMIT City</td>\n",
       "      <td>City precincts</td>\n",
       "      <td>-37.80778</td>\n",
       "      <td>144.96333</td>\n",
       "      <td>349</td>\n",
       "      <td>84</td>\n",
       "      <td>50</td>\n",
       "      <td>829.0</td>\n",
       "      <td>137382.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name        Category  Latitude  Longitude  #photos  \\\n",
       "poiID                                                                      \n",
       "0            Arts Precinct  City precincts -37.82167  144.96778      102   \n",
       "1                Docklands  City precincts -37.81700  144.94600      139   \n",
       "2      Government Precinct  City precincts -37.81190  144.97300      304   \n",
       "3             Little Italy  City precincts -37.79972  144.96694      138   \n",
       "4                RMIT City  City precincts -37.80778  144.96333      349   \n",
       "\n",
       "       #visits  #distinctUsers  medianDuration(sec)  totalDuration(sec)  \n",
       "poiID                                                                    \n",
       "0           73              64                332.5             24600.0  \n",
       "1           52              39                438.5             42491.0  \n",
       "2          116              83               1835.0            141155.0  \n",
       "3           54              44               1971.5             61945.0  \n",
       "4           84              50                829.0            137382.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df.loc[poi_photo.index, '#photos'] = poi_photo['#photos']\n",
    "poi_df.loc[poi_visits_stats.index, '#visits'] = poi_visits_stats['#visits']\n",
    "poi_df.loc[poi_visits_stats.index, '#distinctUsers'] = poi_visits_stats['#distinctUsers']\n",
    "poi_df.loc[poi_duration_stats.index, 'medianDuration(sec)'] = poi_duration_stats['medianDuration(sec)']\n",
    "poi_df.loc[poi_duration_stats.index, 'totalDuration(sec)'] = poi_duration_stats['totalDuration(sec)']\n",
    "poi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. POI vs Photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 POIs with NO Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>#photos</th>\n",
       "      <th>#visits</th>\n",
       "      <th>#distinctUsers</th>\n",
       "      <th>medianDuration(sec)</th>\n",
       "      <th>totalDuration(sec)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Flemington Racecourse</td>\n",
       "      <td>Sports stadiums</td>\n",
       "      <td>-37.79028</td>\n",
       "      <td>144.91250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Royal Melbourne Golf Club</td>\n",
       "      <td>Sports stadiums</td>\n",
       "      <td>-37.97000</td>\n",
       "      <td>145.03000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Yarra River</td>\n",
       "      <td>Transport</td>\n",
       "      <td>-37.85194</td>\n",
       "      <td>144.90833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name         Category  Latitude  Longitude  \\\n",
       "poiID                                                                    \n",
       "54         Flemington Racecourse  Sports stadiums -37.79028  144.91250   \n",
       "64     Royal Melbourne Golf Club  Sports stadiums -37.97000  145.03000   \n",
       "87                   Yarra River        Transport -37.85194  144.90833   \n",
       "\n",
       "       #photos  #visits  #distinctUsers  medianDuration(sec)  \\\n",
       "poiID                                                          \n",
       "54           0        0               0                  0.0   \n",
       "64           0        0               0                  0.0   \n",
       "87           0        0               0                  0.0   \n",
       "\n",
       "       totalDuration(sec)  \n",
       "poiID                      \n",
       "54                    0.0  \n",
       "64                    0.0  \n",
       "87                    0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df[poi_df['#visits'] < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Photo Clusters without Corresponding POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A map with photos in Chinatown of Melbourne, NO geo-coordinates were provided in [its Wikipedia page](https://en.wikipedia.org/wiki/Chinatown,_Melbourne)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Trajectories Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute trajectories using POI visiting records, **assuming NO loops/subtours in trajectories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traj_all = visits[['userID', 'trajID', 'poiID', 'dateTaken']].copy().groupby(['userID', 'trajID', 'poiID'])\\\n",
    "           .agg([np.min, np.max, np.size])\n",
    "traj_all.columns = traj_all.columns.droplevel()\n",
    "traj_all.reset_index(inplace=True)\n",
    "traj_all.rename(columns={'amin':'startTime', 'amax':'endTime', 'size':'#photo'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traj_len = traj_all[['userID', 'trajID', 'poiID']].copy().groupby(['userID', 'trajID']).agg(np.size)\n",
    "traj_len.reset_index(inplace=True)\n",
    "traj_len.rename(columns={'poiID':'trajLen'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>trajID</th>\n",
       "      <th>poiID</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>#photo</th>\n",
       "      <th>trajLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10058801@N06</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1226726126</td>\n",
       "      <td>1226726126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1205332532</td>\n",
       "      <td>1205332541</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1205342722</td>\n",
       "      <td>1205342729</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>1205374109</td>\n",
       "      <td>1205374109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>1205417265</td>\n",
       "      <td>1205417265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1205508764</td>\n",
       "      <td>1205538412</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>1205512653</td>\n",
       "      <td>1205514882</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>1205575764</td>\n",
       "      <td>1205595114</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>1205625724</td>\n",
       "      <td>1205641382</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10087938@N02</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>1205812892</td>\n",
       "      <td>1205812892</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  trajID  poiID   startTime     endTime  #photo  trajLen\n",
       "0  10058801@N06       0     25  1226726126  1226726126       1        1\n",
       "1  10087938@N02       1     58  1205332532  1205332541       2        2\n",
       "2  10087938@N02       1     66  1205342722  1205342729       2        2\n",
       "3  10087938@N02       2     59  1205374109  1205374109       1        1\n",
       "4  10087938@N02       3     58  1205417265  1205417265       1        1\n",
       "5  10087938@N02       4     58  1205508764  1205538412       3        2\n",
       "6  10087938@N02       4     59  1205512653  1205514882      22        2\n",
       "7  10087938@N02       5     59  1205575764  1205595114       4        1\n",
       "8  10087938@N02       6     59  1205625724  1205641382       2        1\n",
       "9  10087938@N02       7     58  1205812892  1205812892       1        1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_all = pd.merge(traj_all, traj_len, on=['userID', 'trajID'])\n",
    "traj_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Example of Terrible Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract trajectory, i.e., a list of POIs, considering loops/subtours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_traj_withloop(tid, visits):\n",
    "    \"\"\"Compute trajectories info, taking care of trajectories that contain sub-tours\"\"\"\n",
    "    traj_df = visits[visits['trajID'] == tid].copy()\n",
    "    traj_df.sort_values(by='dateTaken', ascending=True, inplace=True)\n",
    "    traj = []\n",
    "    for ix in traj_df.index:\n",
    "        poi = traj_df.loc[ix, 'poiID']\n",
    "        if len(traj) == 0:\n",
    "            traj.append(poi)\n",
    "        else:\n",
    "            if poi != traj[-1]:\n",
    "                traj.append(poi)\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract trajectory, i.e., a list of POIs, assuming NO considering loops/subtours exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_traj(tid, traj_all):\n",
    "    traj = traj_all[traj_all['trajID'] == tid].copy()\n",
    "    traj.sort_values(by=['startTime'], ascending=True, inplace=True)\n",
    "    return traj['poiID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tid = traj_all.loc[traj_all['trajLen'].idxmax(), 'trajID']\n",
    "tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 32, 9, 35, 8, 17, 13, 15, 82, 50, 71, 81, 44, 45, 14, 9, 32, 85, 1, 53, 85, 27, 25] length: 23\n"
     ]
    }
   ],
   "source": [
    "traj1 = extract_traj_withloop(tid, visits)\n",
    "print(traj1, 'length:', len(traj1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 32, 9, 35, 8, 17, 13, 15, 82, 50, 71, 81, 44, 45, 14, 85, 1, 53, 27, 25] length: 20\n"
     ]
    }
   ],
   "source": [
    "traj2 = extract_traj(tid, traj_all)\n",
    "print(traj2, 'length:', len(traj2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of this trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute POI properties, e.g., popularity, total number of visit, average visit duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_poi_info(trajid_list, traj_all, poi_all):\n",
    "    assert(len(trajid_list) > 0)\n",
    "    # to allow duplicated trajid\n",
    "    poi_info = traj_all[traj_all['trajID'] == trajid_list[0]][['poiID', 'poiDuration']].copy() \n",
    "    for i in range(1, len(trajid_list)):\n",
    "        traj = traj_all[traj_all['trajID'] == trajid_list[i]][['poiID', 'poiDuration']]\n",
    "        poi_info = poi_info.append(traj, ignore_index=True)\n",
    "    \n",
    "    poi_info = poi_info.groupby('poiID').agg([np.mean, np.size])\n",
    "    poi_info.columns = poi_info.columns.droplevel()\n",
    "    poi_info.reset_index(inplace=True)\n",
    "    poi_info.rename(columns={'mean':'avgDuration', 'size':'nVisit'}, inplace=True)\n",
    "    poi_info.set_index('poiID', inplace=True) \n",
    "    poi_info['poiCat'] = poi_all.loc[poi_info.index, 'poiCat']\n",
    "    poi_info['poiLon'] = poi_all.loc[poi_info.index, 'poiLon']\n",
    "    poi_info['poiLat'] = poi_all.loc[poi_info.index, 'poiLat']\n",
    "    \n",
    "    # POI popularity: the number of distinct users that visited the POI\n",
    "    pop_df = traj_all[traj_all['trajID'].isin(trajid_list)][['poiID', 'userID']].copy()\n",
    "    pop_df = pop_df.groupby('poiID').agg(pd.Series.nunique)\n",
    "    pop_df.rename(columns={'userID':'nunique'}, inplace=True)\n",
    "    poi_info['popularity'] = pop_df.loc[poi_info.index, 'nunique']\n",
    "    \n",
    "    return poi_info.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory, **assuming NO loops/subtours in trajectories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(traj_act, traj_rec):\n",
    "    '''Compute recall, precision and F1 for recommended trajectories'''\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(len(traj_act) > 0)\n",
    "    assert(len(traj_rec) > 0)\n",
    "    \n",
    "    intersize = len(set(traj_act) & set(traj_rec))\n",
    "    recall = intersize / len(traj_act)\n",
    "    precision = intersize / len(traj_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute distance between two POIs using [Haversine formula](http://en.wikipedia.org/wiki/Great-circle_distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_dist_vec(longitudes1, latitudes1, longitudes2, latitudes2):\n",
    "    \"\"\"Calculate the distance (unit: km) between two places on earth, vectorised\"\"\"\n",
    "    # convert degrees to radians\n",
    "    lng1 = np.radians(longitudes1)\n",
    "    lat1 = np.radians(latitudes1)\n",
    "    lng2 = np.radians(longitudes2)\n",
    "    lat2 = np.radians(latitudes2)\n",
    "    radius = 6371.0088 # mean earth radius, en.wikipedia.org/wiki/Earth_radius#Mean_radius\n",
    "\n",
    "    # The haversine formula, en.wikipedia.org/wiki/Great-circle_distance\n",
    "    dlng = np.fabs(lng1 - lng2)\n",
    "    dlat = np.fabs(lat1 - lat2)\n",
    "    dist =  2 * radius * np.arcsin( np.sqrt( \n",
    "                (np.sin(0.5*dlat))**2 + np.cos(lat1) * np.cos(lat2) * (np.sin(0.5*dlng))**2 ))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance between POIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POI_DISTMAT = pd.DataFrame(data=np.zeros((poi_all.shape[0], poi_all.shape[0]), dtype=np.float), \\\n",
    "                           index=poi_all.index, columns=poi_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ix in poi_all.index:\n",
    "    POI_DISTMAT.loc[ix] = calc_dist_vec(poi_all.loc[ix, 'poiLon'], \\\n",
    "                                        poi_all.loc[ix, 'poiLat'], \\\n",
    "                                        poi_all['poiLon'], \\\n",
    "                                        poi_all['poiLat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajid_set_all = sorted(traj_all['trajID'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_info_all = calc_poi_info(trajid_set_all, traj_all, poi_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out POI visits with 0 duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zero_duration = poi_info_all[poi_info_all['avgDuration'] < 1]\n",
    "zero_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(traj_all.shape)\n",
    "traj_all = traj_all[traj_all['poiID'].isin(set(poi_info_all.index) - set(zero_duration.index))]\n",
    "print(traj_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary maps every trajectory ID to the actual trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traj_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for trajid in trajid_set_all:\n",
    "    traj = extract_traj(trajid, traj_all)\n",
    "    assert(trajid not in traj_dict)\n",
    "    traj_dict[trajid] = traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a *query* (in IR terminology) using tuple (start POI, end POI, #POI) ~~user ID.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY_ID_DICT = dict()  # (start, end, length) --> qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = [(traj_dict[x][0], traj_dict[x][-1], len(traj_dict[x])) \\\n",
    "        for x in sorted(traj_dict.keys()) if len(traj_dict[x]) > 2]\n",
    "cnt = 0\n",
    "for key in keys:\n",
    "    if key not in QUERY_ID_DICT:   # (start, end, length) --> qid\n",
    "        QUERY_ID_DICT[key] = cnt\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('#traj in total:', len(trajid_set_all))\n",
    "print('#traj (length > 2):', traj_all[traj_all['trajLen'] > 2]['trajID'].unique().shape[0])\n",
    "print('#query tuple:', len(QUERY_ID_DICT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Recommendation via POI Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 POI Features for Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POI Features used for ranking:\n",
    "1. `popularity`: POI popularity, i.e., the number of distinct users that visited the POI\n",
    "1. `nVisit`: the total number of visit by all users\n",
    "1. `avgDuration`: average POI visit duration\n",
    "1. `sameCatStart`: 1 if POI category is the same as that of `startPOI`, -1 otherwise\n",
    "1. `sameCatEnd`: 1 if POI category is the same as that of `endPOI`, -1 otherwise\n",
    "1. `distStart`: distance (haversine formula) from `startPOI`\n",
    "1. `distEnd`: distance from `endPOI`\n",
    "1. `seqLen`: trajectory length (copy from query)\n",
    "1. `diffPopStart`: difference in POI popularity from `startPOI`\n",
    "1. `diffPopEnd`: difference in POI popularity from `endPOI`\n",
    "1. `diffNVisitStart`: difference in the total number of visit from `startPOI`\n",
    "1. `diffNVisitEnd`: difference in the total number of visit from `endPOI`\n",
    "1. `diffDurationStart`: difference in average POI visit duration from the actual duration spent at `startPOI`\n",
    "1. `diffDurationEnd`: difference in average POI visit duration from the actual duration spent at `endPOI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_COLUMNS = ['poiID', 'label', 'queryID', 'popularity', 'nVisit', 'avgDuration', \\\n",
    "              'sameCatStart', 'sameCatEnd', 'distStart', 'distEnd', 'trajLen', 'diffPopStart', \\\n",
    "              'diffPopEnd', 'diffNVisitStart', 'diffNVisitEnd', 'diffDurationStart', 'diffDurationEnd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Training DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data are generated as follows:\n",
    "1. each input tuple $(\\text{startPOI}, \\text{endPOI}, \\text{#POI})$ form a `query` (in IR terminology).\n",
    "1. the label of a specific POI is the number of presence of that POI in a specific `query`, excluding the presence as $\\text{startPOI}$ or $\\text{endPOI}$.\n",
    "1. for each `query`, the label of all absence POIs from trajectories of that `query` in training set got a label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of training data matrix is `#(qid, poi)` by `#feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_train_subdf(poi_id, query_id_set, poi_info, query_id_rdict):\n",
    "    columns = DF_COLUMNS\n",
    "    poi_distmat = POI_DISTMAT\n",
    "    df_ = pd.DataFrame(data=np.zeros((len(query_id_set), len(columns)), dtype=np.float), columns=columns)\n",
    "    \n",
    "    pop = poi_info.loc[poi_id, 'popularity']; nvisit = poi_info.loc[poi_id, 'nVisit']\n",
    "    cat = poi_info.loc[poi_id, 'poiCat']; duration = poi_info.loc[poi_id, 'avgDuration']\n",
    "    \n",
    "    for j in range(len(query_id_set)):\n",
    "        qid = query_id_set[j]\n",
    "        assert(qid in query_id_rdict) # qid --> (start, end, length)\n",
    "        (p0, pN, trajLen) = query_id_rdict[qid]\n",
    "        idx = df_.index[j]\n",
    "        df_.loc[idx, 'poiID'] = poi_id\n",
    "        df_.loc[idx, 'queryID'] = qid\n",
    "        df_.loc[idx, 'popularity'] = pop\n",
    "        df_.loc[idx, 'nVisit'] = nvisit\n",
    "        df_.loc[idx, 'avgDuration'] = duration\n",
    "        df_.loc[idx, 'sameCatStart'] = 1 if cat == poi_info.loc[p0, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'sameCatEnd']   = 1 if cat == poi_info.loc[pN, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'distStart'] = poi_distmat.loc[poi_id, p0]\n",
    "        df_.loc[idx, 'distEnd']   = poi_distmat.loc[poi_id, pN]\n",
    "        df_.loc[idx, 'trajLen'] = trajLen\n",
    "        df_.loc[idx, 'diffPopStart'] = pop - poi_info.loc[p0, 'popularity']\n",
    "        df_.loc[idx, 'diffPopEnd']   = pop - poi_info.loc[pN, 'popularity']\n",
    "        df_.loc[idx, 'diffNVisitStart'] = nvisit - poi_info.loc[p0, 'nVisit']\n",
    "        df_.loc[idx, 'diffNVisitEnd']   = nvisit - poi_info.loc[pN, 'nVisit']\n",
    "        df_.loc[idx, 'diffDurationStart'] = duration - poi_info.loc[p0, 'avgDuration']\n",
    "        df_.loc[idx, 'diffDurationEnd']   = duration - poi_info.loc[pN, 'avgDuration']\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_train_df(trajid_list, traj_dict, poi_info, n_jobs=-1):\n",
    "    columns = DF_COLUMNS\n",
    "    poi_distmat = POI_DISTMAT\n",
    "    query_id_dict = QUERY_ID_DICT\n",
    "    train_trajs = [traj_dict[x] for x in trajid_list if len(traj_dict[x]) > 2]\n",
    "    \n",
    "    qid_set = sorted(set([query_id_dict[(t[0], t[-1], len(t))] for t in train_trajs]))\n",
    "    poi_set = set()\n",
    "    for tr in train_trajs:\n",
    "        poi_set = poi_set | set(tr)\n",
    "    \n",
    "    #qid_poi_pair = list(itertools.product(qid_set, poi_set)) # Cartesian product of qid_set and poi_set\n",
    "    #df_ = pd.DataFrame(data=np.zeros((len(qid_poi_pair), len(columns)), dtype= np.float), columns=columns)\n",
    "    \n",
    "    query_id_rdict = dict()\n",
    "    for k, v in query_id_dict.items(): \n",
    "        query_id_rdict[v] = k  # qid --> (start, end, length)\n",
    "    \n",
    "    train_df_list = Parallel(n_jobs=n_jobs)\\\n",
    "                            (delayed(gen_train_subdf)(poi, qid_set, poi_info, query_id_rdict) \\\n",
    "                             for poi in poi_set)\n",
    "                        \n",
    "    assert(len(train_df_list) > 0)\n",
    "    df_ = train_df_list[0]\n",
    "    for j in range(1, len(train_df_list)):\n",
    "        df_ = df_.append(train_df_list[j], ignore_index=True)            \n",
    "        \n",
    "    # set label\n",
    "    df_.set_index(['queryID', 'poiID'], inplace=True)\n",
    "    for t in train_trajs:\n",
    "        qid = query_id_dict[(t[0], t[-1], len(t))]\n",
    "        for poi in t[1:-1]:  # do NOT count if the POI is startPOI/endPOI\n",
    "            df_.loc[(qid, poi), 'label'] += 1\n",
    "\n",
    "    df_.reset_index(inplace=True)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: \n",
    "- different POIs have different features for the same query trajectory\n",
    "- the same POI get different features for different query-id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Test DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data are generated the same way as training data, except that the labels of testing data (unknown) could be arbitrary values as suggested in [libsvm FAQ](http://www.csie.ntu.edu.tw/~cjlin/libsvm/faq.html#f431).\n",
    "The reported accuracy (by `svm-predict` command) is meaningless as it is calculated based on these labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of training data matrix is `#poi` by `#feature` with one specific `query`, i.e. tuple $(\\text{startPOI}, \\text{endPOI}, \\text{#POI})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_test_df(startPOI, endPOI, nPOI, poi_info):\n",
    "    columns = DF_COLUMNS\n",
    "    poi_distmat = POI_DISTMAT\n",
    "    query_id_dict = QUERY_ID_DICT\n",
    "    key = (p0, pN, trajLen) = (startPOI, endPOI, nPOI)\n",
    "    assert(key in query_id_dict)\n",
    "    assert(p0 in poi_info.index)\n",
    "    assert(pN in poi_info.index)\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros((poi_info.shape[0], len(columns)), dtype= np.float), columns=columns)\n",
    "    poi_list = sorted(poi_info.index)\n",
    "    \n",
    "    qid = query_id_dict[key]\n",
    "    df_['queryID'] = qid\n",
    "    df_['label'] = np.random.rand(df_.shape[0]) # label for test data is arbitrary according to libsvm FAQ\n",
    "\n",
    "    for i in range(df_.index.shape[0]):\n",
    "        poi = poi_list[i]\n",
    "        lon = poi_info.loc[poi, 'poiLon']; lat = poi_info.loc[poi, 'poiLat']\n",
    "        pop = poi_info.loc[poi, 'popularity']; nvisit = poi_info.loc[poi, 'nVisit']\n",
    "        cat = poi_info.loc[poi, 'poiCat']; duration = poi_info.loc[poi, 'avgDuration']\n",
    "        idx = df_.index[i]\n",
    "        df_.loc[idx, 'poiID'] = poi \n",
    "        df_.loc[idx, 'popularity'] = pop\n",
    "        df_.loc[idx, 'nVisit'] = nvisit\n",
    "        df_.loc[idx, 'avgDuration'] = duration\n",
    "        df_.loc[idx, 'sameCatStart'] = 1 if cat == poi_all.loc[p0, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'sameCatEnd']   = 1 if cat == poi_all.loc[pN, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'distStart'] = poi_distmat.loc[poi, p0]\n",
    "        df_.loc[idx, 'distEnd']   = poi_distmat.loc[poi, pN]\n",
    "        df_.loc[idx, 'trajLen'] = trajLen\n",
    "        df_.loc[idx, 'diffPopStart'] = pop - poi_info.loc[p0, 'popularity']\n",
    "        df_.loc[idx, 'diffPopEnd']   = pop - poi_info.loc[pN, 'popularity']\n",
    "        df_.loc[idx, 'diffNVisitStart'] = nvisit - poi_info.loc[p0, 'nVisit']\n",
    "        df_.loc[idx, 'diffNVisitEnd']   = nvisit - poi_info.loc[pN, 'nVisit']\n",
    "        df_.loc[idx, 'diffDurationStart'] = duration - poi_info.loc[p0, 'avgDuration']\n",
    "        df_.loc[idx, 'diffDurationEnd']   = duration - poi_info.loc[pN, 'avgDuration']\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: \n",
    "- different POIs have different features for the same query trajectory\n",
    "- the same POI get different features for different query-id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a string for a training/test data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data_str(df_, df_columns=DF_COLUMNS):\n",
    "    columns = df_columns[1:].copy()  # get rid of 'poiID'\n",
    "    for col in columns:\n",
    "        assert(col in df_.columns)\n",
    "        \n",
    "    lines = []\n",
    "    for idx in df_.index:\n",
    "        slist = [str(df_.loc[idx, 'label'])]\n",
    "        slist.append(' qid:')\n",
    "        slist.append(str(int(df_.loc[idx, 'queryID'])))\n",
    "        for j in range(2, len(columns)):\n",
    "            slist.append(' ')\n",
    "            slist.append(str(j-1))\n",
    "            slist.append(':')\n",
    "            slist.append(str(df_.loc[idx, columns[j]]))\n",
    "        slist.append('\\n')\n",
    "        lines.append(''.join(slist))\n",
    "    return ''.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Ranking POIs using rankSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankSVM implementation in [libsvm.zip](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/ranksvm/libsvm-ranksvm-3.20.zip) or [liblinear.zip](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/ranksvm/liblinear-ranksvm-1.95.zip), please read `README.ranksvm` in the zip file for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [softmax function](https://en.wikipedia.org/wiki/Softmax_function) to convert ranking scores to a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x1 = x.copy()\n",
    "    x1 -= np.max(x1)  # numerically more stable, REF: http://cs231n.github.io/linear-classify/#softmax\n",
    "    expx = np.exp(x1)\n",
    "    return expx / np.sum(expx, axis=0) # column-wise sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a python wrapper of the `svm-train` or `train` and `svm-predict` or `predict` commands of rankSVM with ranking probabilities $P(p_i \\lvert (p_s, p_e, len))$ computed using [softmax function](https://en.wikipedia.org/wiki/Softmax_function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python wrapper of rankSVM\n",
    "class RankSVM:\n",
    "    def __init__(self, bin_dir, useLinear=True, debug=False):\n",
    "        dir_ = !echo $bin_dir  # deal with environmental variables in path\n",
    "        assert(os.path.exists(dir_[0]))\n",
    "        self.bin_dir = dir_[0]\n",
    "        \n",
    "        self.bin_train = 'svm-train'\n",
    "        self.bin_predict = 'svm-predict'\n",
    "        if useLinear:\n",
    "            self.bin_train = 'train'\n",
    "            self.bin_predict = 'predict'\n",
    "        \n",
    "        assert(isinstance(debug, bool))\n",
    "        self.debug = debug\n",
    "        \n",
    "        # create named tmp files for model and feature scaling parameters\n",
    "        self.fmodel = None\n",
    "        self.fscale = None\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            self.fmodel = fd.name\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            self.fscale = fd.name\n",
    "        \n",
    "        if self.debug:\n",
    "            print('model file:', self.fmodel)\n",
    "            print('feature scaling parameter file:', self.fscale)\n",
    "    \n",
    "    \n",
    "    def __del__(self):\n",
    "        # remove tmp files\n",
    "        if self.fmodel is not None and os.path.exists(self.fmodel):\n",
    "            os.unlink(self.fmodel)\n",
    "        if self.fscale is not None and os.path.exists(self.fscale):\n",
    "            os.unlink(self.fscale)\n",
    "    \n",
    "    \n",
    "    def train(self, train_df, cost=1):\n",
    "        # cost is parameter C in SVM\n",
    "        # write train data to file\n",
    "        ftrain = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as fd: \n",
    "            ftrain = fd.name\n",
    "            datastr = gen_data_str(train_df)\n",
    "            fd.write(datastr)\n",
    "        \n",
    "        # feature scaling\n",
    "        ftrain_scaled = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as fd: \n",
    "            ftrain_scaled = fd.name\n",
    "        result = !$self.bin_dir/svm-scale -s $self.fscale $ftrain > $ftrain_scaled\n",
    "        \n",
    "        if self.debug:\n",
    "            print('cost:', cost)\n",
    "            print('train data file:', ftrain)\n",
    "            print('feature scaled train data file:', ftrain_scaled)\n",
    "        \n",
    "        # train rank svm and generate model file, if the model file exists, rewrite it\n",
    "        #n_cv = 10  # parameter k for k-fold cross-validation, NO model file will be generated in CV mode\n",
    "        #result = !$self.bin_dir/svm-train -c $cost -v $n_cv $ftrain $self.fmodel\n",
    "        result = !$self.bin_dir/$self.bin_train -c $cost $ftrain_scaled $self.fmodel\n",
    "        if self.debug:\n",
    "            print('Training finished.')\n",
    "            for i in range(len(result)): print(result[i])\n",
    "\n",
    "        # remove train data file\n",
    "        os.unlink(ftrain)\n",
    "        os.unlink(ftrain_scaled)        \n",
    "        \n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        # predict ranking scores for the given feature matrix\n",
    "        if self.fmodel is None or not os.path.exists(self.fmodel):\n",
    "            print('Model should be trained before predicting')\n",
    "            return\n",
    "        \n",
    "        # write test data to file\n",
    "        ftest = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as fd: \n",
    "            ftest = fd.name\n",
    "            datastr = gen_data_str(test_df)\n",
    "            fd.write(datastr)\n",
    "                \n",
    "        # feature scaling\n",
    "        ftest_scaled = None\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            ftest_scaled = fd.name\n",
    "        result = !$self.bin_dir/svm-scale -r $self.fscale $ftest > $ftest_scaled\n",
    "            \n",
    "        # generate prediction file\n",
    "        fpredict = None\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            fpredict = fd.name\n",
    "            \n",
    "        if self.debug:\n",
    "            print('test data file:', ftest)\n",
    "            print('feature scaled test data file:', ftest_scaled)\n",
    "            print('predict result file:', fpredict)\n",
    "            \n",
    "        # predict using trained model and write prediction to file\n",
    "        result = !$self.bin_dir/$self.bin_predict $ftest_scaled $self.fmodel $fpredict\n",
    "        if self.debug:\n",
    "            print('Predict result: %-30s  %s' % (result[0], result[1]))\n",
    "        \n",
    "        # generate prediction DataFrame from prediction file\n",
    "        poi_rank_df = pd.read_csv(fpredict, header=None)\n",
    "        poi_rank_df.rename(columns={0:'rank'}, inplace=True)\n",
    "        poi_rank_df['poiID'] = test_df['poiID'].astype(np.int)\n",
    "        poi_rank_df.set_index('poiID', inplace=True) # duplicated 'poiID' when evaluating training data\n",
    "        #poi_rank_df['probability'] = softmax(poi_rank_df['rank'])  # softmax\n",
    "        \n",
    "        # remove test file and prediction file\n",
    "        os.unlink(ftest)\n",
    "        os.unlink(ftest_scaled)\n",
    "        os.unlink(fpredict)\n",
    "        \n",
    "        return poi_rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Factorised Transition Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 POI Features for Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POI features used to factorise transition matrix of Markov Chain with POI features (vector) as states:\n",
    "- Category of POI\n",
    "- Popularity of POI (discritize with uniform log-scale bins, #bins=5 )\n",
    "- The number of POI visits (discritize with uniform log-scale bins, #bins=5 )\n",
    "- The average visit duration of POI (discritise with uniform log-scale bins, #bins= 5)\n",
    "- The neighborhood relationship between POIs (clustering POI(lat, lon) using k-means, #clusters= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of transition first, then normalise each row while taking care of zero by adding each cell a number $k=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_transmat(transmat_cnt):\n",
    "    transmat = transmat_cnt.copy()\n",
    "    assert(isinstance(transmat, pd.DataFrame))\n",
    "    for row in range(transmat.index.shape[0]):\n",
    "        rowsum = np.sum(transmat.iloc[row] + 1)\n",
    "        assert(rowsum > 0)\n",
    "        transmat.iloc[row] = (transmat.iloc[row] + 1) / rowsum\n",
    "    return transmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POIs in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_train = sorted(poi_info_all.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of bins/clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BIN_CLUSTER = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Transition Matrix between POI Cateogries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_cats = poi_all.loc[poi_train, 'poiCat'].unique().tolist()\n",
    "poi_cats.sort()\n",
    "#poi_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_cat(trajid_list, traj_dict, poi_info, poi_cats=poi_cats):\n",
    "    transmat_cat_cnt = pd.DataFrame(data=np.zeros((len(poi_cats), len(poi_cats)), dtype=np.float), \\\n",
    "                                    columns=poi_cats, index=poi_cats)\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                cat1 = poi_info.loc[p1, 'poiCat']\n",
    "                cat2 = poi_info.loc[p2, 'poiCat']\n",
    "                transmat_cat_cnt.loc[cat1, cat2] += 1\n",
    "    return normalise_transmat(transmat_cat_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_transmat_cat(trajid_set_all, traj_dict, poi_info_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Transition Matrix between POI Popularity Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_pops = poi_info_all.loc[poi_train, 'popularity']\n",
    "#sorted(poi_pops.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize POI popularity with uniform log-scale bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expo_pop1 = np.log10(max(1, min(poi_pops)))\n",
    "expo_pop2 = np.log10(max(poi_pops))\n",
    "print(expo_pop1, expo_pop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbins_pop = BIN_CLUSTER\n",
    "logbins_pop = np.logspace(np.floor(expo_pop1), np.ceil(expo_pop2), nbins_pop+1)\n",
    "logbins_pop[0] = 0  # deal with underflow\n",
    "if uspecific == True:\n",
    "    logbins_pop[-1] = KX * logbins_pop[-1]  # deal with overflow\n",
    "if logbins_pop[-1] < poi_info_all['popularity'].max():\n",
    "    logbins_pop[-1] = poi_info_all['popularity'].max() + 1\n",
    "logbins_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pd.Series(poi_pops).hist(figsize=(5, 3), bins=logbins_pop)\n",
    "ax.set_xlim(xmin=0.1)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_pop(trajid_list, traj_dict, poi_info, logbins_pop=logbins_pop):\n",
    "    nbins = len(logbins_pop) - 1\n",
    "    transmat_pop_cnt = pd.DataFrame(data=np.zeros((nbins, nbins), dtype=np.float), \\\n",
    "                                    columns=np.arange(1, nbins+1), index=np.arange(1, nbins+1))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                pop1 = poi_info.loc[p1, 'popularity']\n",
    "                pop2 = poi_info.loc[p2, 'popularity']\n",
    "                pc1, pc2 = np.digitize([pop1, pop2], logbins_pop)\n",
    "                transmat_pop_cnt.loc[pc1, pc2] += 1\n",
    "    return normalise_transmat(transmat_pop_cnt), logbins_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_transmat_pop(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Transition Matrix between the Number of POI Visit Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_visits = poi_info_all.loc[poi_train, 'nVisit']\n",
    "#sorted(poi_visits.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize the number of POI visit with uniform log-scale bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expo_visit1 = np.log10(max(1, min(poi_visits)))\n",
    "expo_visit2 = np.log10(max(poi_visits))\n",
    "print(expo_visit1, expo_visit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbins_visit = BIN_CLUSTER\n",
    "logbins_visit = np.logspace(np.floor(expo_visit1), np.ceil(expo_visit2), nbins_visit+1)\n",
    "logbins_visit[0] = 0  # deal with underflow\n",
    "if uspecific == True:\n",
    "    logbins_visit[-1] = KX * logbins_visit[-1]  # deal with overflow\n",
    "if logbins_visit[-1] < poi_info_all['nVisit'].max():\n",
    "    logbins_visit[-1] = poi_info_all['nVisit'].max() + 1\n",
    "logbins_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pd.Series(poi_visits).hist(figsize=(5, 3), bins=logbins_visit)\n",
    "ax.set_xlim(xmin=0.1)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_visit(trajid_list, traj_dict, poi_info, logbins_visit=logbins_visit):\n",
    "    nbins = len(logbins_visit) - 1\n",
    "    transmat_visit_cnt = pd.DataFrame(data=np.zeros((nbins, nbins), dtype=np.float), \\\n",
    "                                      columns=np.arange(1, nbins+1), index=np.arange(1, nbins+1))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                visit1 = poi_info.loc[p1, 'nVisit']\n",
    "                visit2 = poi_info.loc[p2, 'nVisit']\n",
    "                vc1, vc2 = np.digitize([visit1, visit2], logbins_visit)\n",
    "                transmat_visit_cnt.loc[vc1, vc2] += 1\n",
    "    return normalise_transmat(transmat_visit_cnt), logbins_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_transmat_visit(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Transition Matrix between POI Average Visit Duration Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_durations = poi_info_all.loc[poi_train, 'avgDuration']\n",
    "#sorted(poi_durations.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expo_duration1 = np.log10(max(1, min(poi_durations)))\n",
    "expo_duration2 = np.log10(max(poi_durations))\n",
    "print(expo_duration1, expo_duration2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbins_duration = BIN_CLUSTER\n",
    "logbins_duration = np.logspace(np.floor(expo_duration1), np.ceil(expo_duration2), nbins_duration+1)\n",
    "logbins_duration[0] = 0  # deal with underflow\n",
    "if uspecific == True:\n",
    "    logbins_duration[-1] = KX * logbins_duration[-1]  # deal with overflow\n",
    "else:\n",
    "    logbins_duration[-1] = np.power(10, expo_duration2+2)\n",
    "logbins_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pd.Series(poi_durations).hist(figsize=(5, 3), bins=logbins_duration)\n",
    "ax.set_xlim(xmin=0.1)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_duration(trajid_list, traj_dict, poi_info, logbins_duration=logbins_duration):\n",
    "    nbins = len(logbins_duration) - 1\n",
    "    transmat_duration_cnt = pd.DataFrame(data=np.zeros((nbins, nbins), dtype=np.float), \\\n",
    "                                         columns=np.arange(1, nbins+1), index=np.arange(1, nbins+1))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                d1 = poi_info.loc[p1, 'avgDuration']\n",
    "                d2 = poi_info.loc[p2, 'avgDuration']\n",
    "                dc1, dc2 = np.digitize([d1, d2], logbins_duration)\n",
    "                transmat_duration_cnt.loc[dc1, dc2] += 1\n",
    "    return normalise_transmat(transmat_duration_cnt), logbins_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_transmat_duration(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Transition Matrix between POI Neighborhood Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans in scikit-learn seems unable to use custom distance metric and no implementation of [Haversine formula](http://en.wikipedia.org/wiki/Great-circle_distance), use Euclidean distance to approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = poi_all.loc[poi_train, ['poiLon', 'poiLat']]\n",
    "nclusters = BIN_CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=nclusters)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(X)\n",
    "#clusters\n",
    "poi_clusters = pd.DataFrame(data=clusters, index=poi_train)\n",
    "poi_clusters.index.name = 'poiID'\n",
    "poi_clusters.rename(columns={0:'clusterID'}, inplace=True)\n",
    "#poi_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot of POI coordinates with clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = poi_all.loc[poi_train, ['poiLon', 'poiLat']].max() - poi_all.loc[poi_train, ['poiLon', 'poiLat']].min()\n",
    "ratio = diff['poiLon'] / diff['poiLat']\n",
    "#ratio\n",
    "height = 6; width = int(round(ratio)*height)\n",
    "plt.figure(figsize=[width, height])\n",
    "plt.scatter(poi_all.loc[poi_train, 'poiLon'], poi_all.loc[poi_train, 'poiLat'], c=clusters, s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_neighbor(trajid_list, traj_dict, poi_info, poi_clusters=poi_clusters):\n",
    "    nclusters = len(poi_clusters['clusterID'].unique())\n",
    "    transmat_neighbor_cnt = pd.DataFrame(data=np.zeros((nclusters, nclusters), dtype=np.float), \\\n",
    "                                         columns=np.arange(nclusters), index=np.arange(nclusters))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                c1 = poi_clusters.loc[p1, 'clusterID']\n",
    "                c2 = poi_clusters.loc[p2, 'clusterID']\n",
    "                transmat_neighbor_cnt.loc[c1, c2] += 1\n",
    "    return normalise_transmat(transmat_neighbor_cnt), poi_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_transmat_neighbor(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Transition Matrix between POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate transition probabilities (matrix) between different POI features (vector) using the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product) of individual transition matrix corresponding to each feature, i.e., POI category, POI popularity (discritized), POI average visit duration (discritized) and POI neighborhoods (clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with features without corresponding POIs and feature with more than one corresponding POIs. (*Before Normalisation*)\n",
    "- For features without corresponding POIs, just remove the rows and columns from the matrix obtained by Kronecker product.\n",
    "- For different POIs with the exact same feature, \n",
    "  - Let POIs with the same feature as a POI group,\n",
    "  - The *incoming* **transition value (i.e., unnormalised transition probability)** of this POI group \n",
    "    should be divided uniformly among the group members, \n",
    "    *which corresponds to choose a group member uniformly at random in the incoming case*.\n",
    "  - The *outgoing* transition value should be duplicated (i.e., the same) among all group members, \n",
    "    **as we were already in that group in the outgoing case**.\n",
    "  - For each POI in the group, the allocation transition value of the *self-loop of the POI group* is similar to \n",
    "    that in the *outgoing* case, **as we were already in that group**, so just duplicate and then divide uniformly among \n",
    "    the transitions from this POI to other POIs in the same group, \n",
    "    *which corresponds to choose a outgoing transition uniformly at random from all outgoing transitions\n",
    "    excluding the self-loop of this POI*.\n",
    "- **Concretely**, for a POI group with $n$ POIs, \n",
    "    1. If the *incoming* transition value of POI group is $m_1$,\n",
    "       then the corresponding *incoming* transition value for each group member is $\\frac{m_1}{n}$.\n",
    "    1. If the *outgoing* transition value of POI group is $m_2$,\n",
    "       then the corresponding *outgoing* transition value for each group member is also $m_2$.\n",
    "    1. If the transition value of *self-loop of the POI group* is $m_3$,\n",
    "       then transition value of *self-loop of individual POIs* should be $0$,  \n",
    "       and *other in-group transitions* with value $\\frac{m_3}{n-1}$\n",
    "       as the total number of outgoing transitions to other POIs in the same group is $n-1$ (excluding the self-loop),\n",
    "       i.e. $n-1$ choose $1$.\n",
    "       \n",
    "**NOTE**: execute the above division before or after row normalisation will lead to the same result, *as the division itself does NOT change the normalising constant of each row (i.e., the sum of each row before normalising)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_poi_transmat(trajid_list, poi_set, traj_dict, poi_info, debug=False):\n",
    "    transmat_cat                        = gen_transmat_cat(trajid_list, traj_dict, poi_info)\n",
    "    transmat_pop,      logbins_pop      = gen_transmat_pop(trajid_list, traj_dict, poi_info)\n",
    "    transmat_visit,    logbins_visit    = gen_transmat_visit(trajid_list, traj_dict, poi_info)\n",
    "    transmat_duration, logbins_duration = gen_transmat_duration(trajid_list, traj_dict, poi_info)\n",
    "    transmat_neighbor, poi_clusters     = gen_transmat_neighbor(trajid_list, traj_dict, poi_info)\n",
    "\n",
    "    # Kronecker product\n",
    "    transmat_ix = list(itertools.product(transmat_cat.index, transmat_pop.index, transmat_visit.index, \\\n",
    "                                         transmat_duration.index, transmat_neighbor.index))\n",
    "    transmat_value = transmat_cat.values\n",
    "    for transmat in [transmat_pop, transmat_visit, transmat_duration, transmat_neighbor]:\n",
    "        transmat_value = kron(transmat_value, transmat.values)\n",
    "    transmat_feature = pd.DataFrame(data=transmat_value, index=transmat_ix, columns=transmat_ix)\n",
    "    \n",
    "    poi_train = sorted(poi_set)\n",
    "    feature_names = ['poiCat', 'popularity', 'nVisit', 'avgDuration', 'clusterID']\n",
    "    poi_features = pd.DataFrame(data=np.zeros((len(poi_train), len(feature_names))), \\\n",
    "                                columns=feature_names, index=poi_train)\n",
    "    poi_features.index.name = 'poiID'\n",
    "    poi_features['poiCat'] = poi_info.loc[poi_train, 'poiCat']\n",
    "    poi_features['popularity'] = np.digitize(poi_info.loc[poi_train, 'popularity'], logbins_pop)\n",
    "    poi_features['nVisit'] = np.digitize(poi_info.loc[poi_train, 'nVisit'], logbins_visit)\n",
    "    poi_features['avgDuration'] = np.digitize(poi_info.loc[poi_train, 'avgDuration'], logbins_duration)\n",
    "    poi_features['clusterID'] = poi_clusters.loc[poi_train, 'clusterID']\n",
    "    \n",
    "    # shrink the result of Kronecker product and deal with POIs with the same features\n",
    "    poi_logtransmat = pd.DataFrame(data=np.zeros((len(poi_train), len(poi_train)), dtype=np.float), \\\n",
    "                                   columns=poi_train, index=poi_train)\n",
    "    for p1 in poi_logtransmat.index:\n",
    "        rix = tuple(poi_features.loc[p1])\n",
    "        for p2 in poi_logtransmat.columns:\n",
    "            cix = tuple(poi_features.loc[p2])\n",
    "            value_ = transmat_feature.loc[(rix,), (cix,)]\n",
    "            poi_logtransmat.loc[p1, p2] = value_.values[0, 0]\n",
    "    \n",
    "    # group POIs with the same features\n",
    "    features_dup = dict()\n",
    "    for poi in poi_features.index:\n",
    "        key = tuple(poi_features.loc[poi])\n",
    "        if key in features_dup:\n",
    "            features_dup[key].append(poi)\n",
    "        else:\n",
    "            features_dup[key] = [poi]\n",
    "    if debug == True:\n",
    "        for key in sorted(features_dup.keys()):\n",
    "            print(key, '->', features_dup[key])\n",
    "            \n",
    "    # deal with POIs with the same features\n",
    "    for feature in sorted(features_dup.keys()):\n",
    "        n = len(features_dup[feature])\n",
    "        if n > 1:\n",
    "            group = features_dup[feature]\n",
    "            v1 = poi_logtransmat.loc[group[0], group[0]]  # transition value of self-loop of POI group\n",
    "            \n",
    "            # divide incoming transition value (i.e. unnormalised transition probability) uniformly among group members\n",
    "            for poi in group:\n",
    "                poi_logtransmat[poi] /= n\n",
    "                \n",
    "            # outgoing transition value has already been duplicated (value copied above)\n",
    "            \n",
    "            # duplicate & divide transition value of self-loop of POI group uniformly among all outgoing transitions,\n",
    "            # from a POI to all other POIs in the same group (excluding POI self-loop)\n",
    "            v2 = v1 / (n - 1)\n",
    "            for pair in itertools.permutations(group, 2):\n",
    "                poi_logtransmat.loc[pair[0], pair[1]] = v2\n",
    "                            \n",
    "    # normalise each row\n",
    "    for p1 in poi_logtransmat.index:\n",
    "        poi_logtransmat.loc[p1, p1] = 0\n",
    "        rowsum = poi_logtransmat.loc[p1].sum()\n",
    "        assert(rowsum > 0)\n",
    "        logrowsum = np.log10(rowsum)\n",
    "        for p2 in poi_logtransmat.columns:\n",
    "            if p1 == p2:\n",
    "                poi_logtransmat.loc[p1, p2] = -np.inf  # deal with log(0) explicitly\n",
    "            else:\n",
    "                poi_logtransmat.loc[p1, p2] = np.log10(poi_logtransmat.loc[p1, p2]) - logrowsum\n",
    "    \n",
    "    poi_transmat = np.power(10, poi_logtransmat)\n",
    "    return poi_transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transmat_ = gen_poi_transmat(trajid_set_all, set(poi_info_all.index), traj_dict, poi_info_all, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Visualise Transition Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot transition matrix heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_mat = np.power(10, poi_logtransmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[13, 10])\n",
    "#plt.imshow(prob_mat, interpolation='none', cmap=plt.cm.hot)  # OK\n",
    "#ticks = prob_mat.index\n",
    "#plt.xticks(np.arange(prob_mat.shape[0]), ticks)\n",
    "#plt.yticks(np.arange(prob_mat.shape[0]), ticks)\n",
    "#plt.xlabel('POI ID')\n",
    "#plt.ylabel('POI ID')\n",
    "sns.heatmap(prob_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise transitions of the most popular POI on map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = kml.KML()\n",
    "ns = '{http://www.opengis.net/kml/2.2}'\n",
    "width_set = set()\n",
    "\n",
    "# Placemark for edges\n",
    "pm_list = []\n",
    "for poi1 in poi_all.index:\n",
    "    for poi2 in poi_all.index:\n",
    "        width = edge_count.loc[poi1, poi2]\n",
    "        if width < 1: continue\n",
    "        width_set.add(width)\n",
    "        sid = str(poi1) + '_' + str(poi2)\n",
    "        desc = 'Edge: ' + str(poi1) + '->' + str(poi2) + ', #occurrence: ' + str(width)\n",
    "        pm = kml.Placemark(ns, sid, 'Edge_' + sid, desc, styleUrl='#sty' + str(width))\n",
    "        pm.geometry = LineString([(poi_all.loc[x, 'poiLon'], poi_all.loc[x, 'poiLat']) for x in [poi1, poi2]])\n",
    "        pm_list.append(pm)\n",
    "\n",
    "# Placemark for POIs\n",
    "for poi in poi_all.index:\n",
    "    sid = str(poi)\n",
    "    desc = 'POI of category ' + poi_all.loc[poi, 'poiTheme']\n",
    "    pm = kml.Placemark(ns, sid, 'POI_' + sid, desc, styleUrl='#sty1')\n",
    "    pm.geometry = Point(poi_all.loc[poi, 'poiLon'], poi_all.loc[poi, 'poiLat'])\n",
    "    pm_list.append(pm)\n",
    "\n",
    "# Styles\n",
    "stys = []\n",
    "for width in width_set:\n",
    "    sid = 'sty' + str(width)\n",
    "    # colors in KML: aabbggrr, aa=00 is fully transparent\n",
    "    stys.append(styles.Style(id=sid, styles=[styles.LineStyle(color='3f0000ff', width=width)])) # transparent red\n",
    "\n",
    "doc = kml.Document(ns, '1', 'Edges', 'Edge visualization', styles=stys)\n",
    "for pm in pm_list: doc.append(pm)\n",
    "k.append(doc)\n",
    "\n",
    "# save to file\n",
    "fname = suffix + '-common_edges.kml'\n",
    "fname = os.path.join(data_dir, fname)\n",
    "kmlstr = k.to_string(prettyprint=True)\n",
    "with open(fname, 'w') as f:\n",
    "    f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    f.write(kmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Leave-one-out Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_crf == True:\n",
    "    recdict_crf = dict()\n",
    "    cost = 10\n",
    "    n_jobs = 4\n",
    "    cnt = 1\n",
    "    for i in range(len(trajid_set_all)):\n",
    "        t0 = time.time()\n",
    "        tid_ = trajid_set_all[i]\n",
    "        te = traj_dict[tid_]\n",
    "        \n",
    "        # trajectory too short\n",
    "        if len(te) < 3: continue\n",
    "            \n",
    "        trajid_list_train = trajid_set_all[:i] + trajid_set_all[i+1:]\n",
    "        poi_info = calc_poi_info(trajid_list_train, traj_all, poi_all)\n",
    "        \n",
    "        assert(len(te) <= poi_info.shape[0])\n",
    "            \n",
    "        # build POI_ID <--> POI__INDEX mapping for POIs used to train CRF\n",
    "        # which means only POIs in traj such that len(traj) >= 3 are included\n",
    "        poi_set = set()\n",
    "        for x in trajid_list_train:\n",
    "            if len(traj_dict[x]) >= 3:\n",
    "                poi_set = poi_set | set(traj_dict[x])                \n",
    "        poi_ix = sorted(poi_set)\n",
    "        poi_id_dict, poi_id_rdict = dict(), dict()\n",
    "        for idx, poi in enumerate(poi_ix):\n",
    "            poi_id_dict[poi] = idx\n",
    "            poi_id_rdict[idx] = poi\n",
    "            \n",
    "        # start/end is not in training set\n",
    "        if not (te[0] in poi_set and te[-1] in poi_set): continue\n",
    "            \n",
    "        print(te, '#%d ->' % cnt); cnt += 1; sys.stdout.flush()\n",
    "        \n",
    "        t1 = time.time()\n",
    "        \n",
    "        # POI feature based ranking\n",
    "        train_df = gen_train_df(trajid_list_train, traj_dict, poi_info, n_jobs)\n",
    "        ranksvm = RankSVM(ranksvm_dir, useLinear=True)\n",
    "        ranksvm.train(train_df, cost=cost)\n",
    "        \n",
    "        t2 = time.time()\n",
    "               \n",
    "        poi_transmat = gen_poi_transmat(trajid_list_train, set(poi_ix), traj_dict, poi_info) \n",
    "        assert(poi_transmat.shape[0] == poi_transmat.shape[1] == len(poi_ix))\n",
    "        transmat_mapped = np.zeros_like(poi_transmat)\n",
    "        for ix in range(len(poi_ix)):  # reorder the transition probabilites according to the order of mapped POIs\n",
    "            pi = poi_ix[ix]\n",
    "            for jx in range(len(poi_ix)):\n",
    "                pj = poi_ix[jx]\n",
    "                transmat_mapped[ix, jx] = poi_transmat.loc[pi, pj]\n",
    "        \n",
    "        t3 = time.time()\n",
    "            \n",
    "        # generate training data\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        train_traj_list = [traj_dict[x] for x in trajid_list_train if len(traj_dict[x]) > 2]\n",
    "        train_df_list = Parallel(n_jobs=n_jobs)(delayed(gen_test_df)(tr[0], tr[-1], len(tr), poi_info) \\\n",
    "                                                for tr in train_traj_list)\n",
    "        rank_df_list = [ranksvm.predict(tr_df) for tr_df in train_df_list]\n",
    "        assert(len(train_traj_list) == len(rank_df_list))\n",
    "        X_train = Parallel(n_jobs=n_jobs)\\\n",
    "                          (delayed(gen_features)\\\n",
    "                           (train_traj_list[x][0], train_traj_list[x][-1], len(train_traj_list[x]), rank_df_list[x], \\\n",
    "                            transmat_mapped, poi_ix, poi_id_dict) for x in range(len(rank_df_list)))\n",
    "        y_train = [np.array([poi_id_dict[x] for x in tr]) for tr in train_traj_list]\n",
    "        assert(len(train_traj_list) == len(X_train) == len(y_train))\n",
    "        #for ix in range(len(X_train)):\n",
    "        #    print('edge features of', train_traj_list[ix])\n",
    "        #    print(X_train[ix][2])\n",
    "        \n",
    "        #for j in range(len(train_set)):\n",
    "        #    tr = traj_dict[train_set[j]]\n",
    "        #    assert(len(tr) >= 3)\n",
    "        #    tr_df = train_df_list[j]\n",
    "        #    tr_rank_df = ranksvm.predict(tr_df)\n",
    "        #    X_train.append(gen_features(tr[0], tr[-1], len(tr), tr_rank_df, transmat_mapped, poi_ix, poi_id_dict))\n",
    "        #    y_train.append(np.array([poi_id_dict[x] for x in tr]))\n",
    "        \n",
    "        t4 = time.time()        \n",
    "                \n",
    "        # train\n",
    "        crf = EdgeFeatureGraphCRF(inference_method='max-product')  # use belief propagation as it is essentially a chain\n",
    "        #ssvm = OneSlackSSVM(model=crf, C=C, max_iter=maxIter, n_jobs=4) # default: C=1, max_iter=10000, n_jobs=1\n",
    "        ssvm = OneSlackSSVM(model=crf, C=C) # optimized BLAS libraries, e.g. OpenBLAS/MKL will use all available threads \n",
    "        ssvm.fit(X_train, y_train)\n",
    "        \n",
    "        t5 = time.time()\n",
    "        \n",
    "        # generate test data\n",
    "        X_test = []\n",
    "        te_df = gen_test_df(te[0], te[-1], len(te), poi_info)\n",
    "        te_rank_df = ranksvm.predict(te_df)\n",
    "        #te_rank_df.set_index('poiID', inplace=True)\n",
    "        X_test.append(gen_features(te[0], te[-1], len(te), te_rank_df, transmat_mapped, \\\n",
    "                                   poi_ix, poi_id_dict))\n",
    "        \n",
    "        # test\n",
    "        y_pred = ssvm.predict(X_test)\n",
    "        rec = [poi_id_rdict[x] for x in y_pred[0]] # map POIs back\n",
    "        rec1 = [te[0]] + rec[1:-1] + [te[-1]]\n",
    "        F1_test.append(calc_F1(te, rec1))\n",
    "        \n",
    "        # test on training set\n",
    "        #y_pred_train = ssvm.predict(X_train)\n",
    "        #F1_train = []\n",
    "        #assert(len(train_set) == len(y_pred_train))\n",
    "        #for j in range(len(train_set)):\n",
    "        #    tr = traj_dict[train_set[j]]\n",
    "        #    F1_train.append(calc_F1(tr, [tr[0]] + [poi_id_rdict[x] for x in y_pred_train[j][1:-1]] + [tr[-1]]))\n",
    "        #F1_train_list.append(F1_train)\n",
    "        \n",
    "        recdict_crf[tid_] = {'REAL':te, 'REC_CRF':rec1} \n",
    "        \n",
    "        t6 = time.time()\n",
    "        \n",
    "        print(' '*10, rec)\n",
    "        print(' '*10, 'rank: %.1f sec, transition: %.1f sec, train_data: %.1f sec, train: %.1f sec, total: %.1f sec' % \\\n",
    "              (t2 - t1, t3 - t2, t4 - t3, t5 - t4, t6 - t0))\n",
    "        #print(' '*10, 'Train F1: %.3f %.3f, Test F1: %.3f' % (np.mean(F1_train), np.std(F1_train), F1_test[-1]))\n",
    "        print(' '*10, 'Test F1: %.3f' % F1_test[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Recommendation Results Comparison & Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of recommendation results: recommendation based on POI popularity, POI ranking and POI transition matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise recommendation results on map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_kml(fname, poi_df):\n",
    "    k = kml.KML()\n",
    "    ns = '{http://www.opengis.net/kml/2.2}'\n",
    "    styid = 'style1'\n",
    "    # colors in KML: aabbggrr, aa=00 is fully transparent\n",
    "    sty = styles.Style(id=styid, styles=[styles.LineStyle(color='9f0000ff', width=2)]) # transparent red\n",
    "    doc = kml.Document(ns, '1', 'POIs', 'POIs visualization', styles=[sty])\n",
    "    k.append(doc)\n",
    "    \n",
    "    # Placemark for POIs\n",
    "    for ix in poi_df.index:\n",
    "        name = poi_df.loc[ix, 'poiName']\n",
    "        cat  = poi_df.loc[ix, 'poiTheme']\n",
    "        lat  = poi_df.loc[ix, 'poiLat']\n",
    "        lon  = poi_df.loc[ix, 'poiLon']\n",
    "        desc = ''.join(['POI Name: ', name, '<br/>Category: ', cat, '<br/>Coordinates: (%f, %f)' % (lat, lon)])\n",
    "        pm = kml.Placemark(ns, str(ix), name, desc, styleUrl='#' + styid)\n",
    "        pm.geometry = Point(lon, lat)\n",
    "        doc.append(pm)\n",
    "        \n",
    "    # save to file\n",
    "    kmlstr = k.to_string(prettyprint=True)\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        f.write(kmlstr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
